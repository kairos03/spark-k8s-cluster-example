[[package]]
name = "py4j"
version = "0.10.9.5"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyspark"
version = "3.3.0"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
py4j = "0.10.9.5"

[package.extras]
ml = ["numpy (>=1.15)"]
mllib = ["numpy (>=1.15)"]
pandas_on_spark = ["numpy (>=1.15)", "pandas (>=1.0.5)", "pyarrow (>=1.0.0)"]
sql = ["pandas (>=1.0.5)", "pyarrow (>=1.0.0)"]

[[package]]
name = "pyspark-gcs"
version = "2.2.6.1"
description = "pyspark with GCS batteries"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
pyspark = "*"

[metadata]
lock-version = "1.1"
python-versions = "^3.8"
content-hash = "002a097f1f4188217754c2b3fd97f8802627d217e91892272c085ecb16ae770a"

[metadata.files]
py4j = [
    {file = "py4j-0.10.9.5-py2.py3-none-any.whl", hash = "sha256:52d171a6a2b031d8a5d1de6efe451cf4f5baff1a2819aabc3741c8406539ba04"},
    {file = "py4j-0.10.9.5.tar.gz", hash = "sha256:276a4a3c5a2154df1860ef3303a927460e02e97b047dc0a47c1c3fb8cce34db6"},
]
pyspark = [
    {file = "pyspark-3.3.0.tar.gz", hash = "sha256:7ebe8e9505647b4d124d5a82fca60dfd3891021cf8ad6c5ec88777eeece92cf7"},
]
pyspark-gcs = [
    {file = "pyspark_gcs-2.2.6.1-py3-none-any.whl", hash = "sha256:6a02c67be0c8eed5e609e6d3a3d56694756e2863385e5c2f84eefd80f0022679"},
    {file = "pyspark_gcs-2.2.6.1.tar.gz", hash = "sha256:1fc96c42cb7fd57d2e3fa1a332050c90874ababe16518a270836071978ca748d"},
]
